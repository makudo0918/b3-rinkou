{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCwAFvVupm8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7971ad8-bf4c-4f28-af00-f22b786e7428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.2543308734893799\n",
            "1001 0.1666666716337204\n",
            "2001 0.1666666716337204\n",
            "3001 0.5787854790687561\n",
            "4001 0.16666674613952637\n",
            "5001 0.1666666567325592\n",
            "6001 0.1666666567325592\n",
            "7001 276.5086364746094\n",
            "8001 0.1666666567325592\n",
            "9001 0.1666666567325592\n",
            "10001 0.1666666716337204\n",
            "11001 0.1666666716337204\n",
            "12001 0.1666666567325592\n",
            "13001 0.1666666865348816\n",
            "14001 0.1666666567325592\n",
            "15001 31.928205490112305\n",
            "16001 0.16679000854492188\n",
            "17001 0.1666666567325592\n",
            "18001 0.3007473349571228\n",
            "19001 0.17600804567337036\n",
            "20001 0.16666683554649353\n",
            "21001 0.1666666567325592\n",
            "22001 276.0630798339844\n",
            "23001 0.16684535145759583\n",
            "24001 0.1666666567325592\n",
            "25001 96.82171630859375\n",
            "26001 0.16796886920928955\n",
            "27001 0.1666666716337204\n",
            "28001 0.1666666567325592\n",
            "29001 3.0182108879089355\n",
            "30001 0.1857365220785141\n",
            "31001 0.16666670143604279\n",
            "32001 0.1666666567325592\n",
            "33001 4.24293327331543\n",
            "34001 0.16672247648239136\n",
            "35001 0.1666666716337204\n",
            "36001 0.1666666567325592\n",
            "37001 0.8729106187820435\n",
            "38001 0.1666668802499771\n",
            "39001 0.1666666716337204\n",
            "40001 6.9244585037231445\n",
            "41001 0.16667351126670837\n",
            "42001 0.1666666716337204\n",
            "43001 41.47693634033203\n",
            "44001 0.16771042346954346\n",
            "45001 0.1666666716337204\n",
            "46001 0.1666666567325592\n",
            "47001 0.2533319592475891\n",
            "48001 0.16666671633720398\n",
            "49001 0.1666666567325592\n",
            "tensor([6.5656], grad_fn=<AddBackward0>)\n",
            "tensor([10.3484], grad_fn=<AddBackward0>)\n",
            "tensor([6.5656], grad_fn=<AddBackward0>)\n",
            "tensor([6.5656], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#1191201088 千葉 竜樹\n",
        "\n",
        "#課題 XOR問題に対して、上記のように学習率を変えたときの学習の変化についてまとめなさい。\n",
        "#SGDだと、0.25程度、5e-11程度、ずっとnan\n",
        "#Adamにするとそれぞれ、11001くらいで0になった、激しく振動して0.00015くらいに、1/6くらいの値が多いがたまに極端に大きな値になる\n",
        "\n",
        "#0.1, 0.001, 100?\n",
        "#学習率を小さくしすぎると、なかなか収束しないし、学習率を大きくしすぎると、うまく収束できない。\n",
        "#torch.optim.Adam()を使用するとよい。\n",
        "#ニューラルネットワークの層数が増えると、いくつかの局所最適値が現れてきて、停留する部分がある。\n",
        "#勾配は、結合荷重の修正量に影響を及ぼす。\n",
        "#入力層に近いほど勾配の大きさが小さいので、結合層をただ重ねるだけでは、結合荷重の修正があまり進まない。\n",
        "#各層ごとに活性化関数が含まれており、誤差が層を通過して前の層に戻すときに、活性化関数の微分がかけられるからだ。\n",
        "#活性化関数がない場合は、勾配消失は緩やかである。結合荷重は平均0のガウス分布で初期化されるため、非常に小さな値を持っているからだ。\n",
        "#活性化関数と結合荷重を複数積み重ねると、深い層の勾配が急激に小さくなる。\n",
        "\n",
        "#XORのニューラルネットワークはそのまま持ってきて、lrの値だけ変える？\n",
        "#torch.optim.Adam()の使い方がよくわからん\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MLP2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(MLP2, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = torch.sigmoid(self.l1(x))\n",
        "    o = self.l2(h)\n",
        "    return o\n",
        "\n",
        "x = [[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]]\n",
        "y = [[0.0], [1.0], [1.0], [0.0]]\n",
        "x = torch.tensor(x)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "model = MLP2(2, 3, 1)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1.0e+3)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1.0e+2)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i in range(50000):\n",
        "  pred = model(x)\n",
        "  error = criterion(pred, y)\n",
        "  if i % 1000 == 0:\n",
        "    print(i+1, error.item())\n",
        "  optimizer.zero_grad()\n",
        "  error.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(model(torch.tensor([0.0, 0.0])))\n",
        "print(model(torch.tensor([0.0, 1.0])))\n",
        "print(model(torch.tensor([1.0, 0.0])))\n",
        "print(model(torch.tensor([1.0, 1.0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1191201088 千葉 竜樹\n",
        "\n",
        "#課題 パリティビットを予測する3層ニューラルネットワークの出力を2つにし、交差エントロピーを誤差関数とした場合のプログラムを作成しなさい。\n",
        "#torch.nn.CrossEntropyLoss()の使い方についてはWeb上で調べること。\n",
        "\n",
        "\n",
        "#パリティビット\n",
        "#3層\n",
        "#出力が2つ\n",
        "#誤差関数が交差エントロピー\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "#ソフトマックス関数\n",
        "#多クラス分類の出力層でよく利用される活性化関数である。一般的にmax関数ではただ一つの出力のみが選ばれるが、ソフトマックス関数は値の差を強調して出力する関数である。\n",
        "#また、出力の総和が1であることから、確率とみなすことも可能である。\n",
        "#fi(x)=exi∑iexi\n",
        "\n",
        "def softmax(x):\n",
        "  exp = np.exp(x,dtype=torch.float)\n",
        "  sum_exp = np.sum(exp)\n",
        "  return exp/sum_exp\n",
        "\n",
        "#def grad_softmax(x):\n",
        "#  y = softmax(x)\n",
        "#  tmp = np.zeros(y.shape)\n",
        "#  tmp[100] = 1.0\n",
        "#  return y * (tmp - y)\n",
        "\n",
        "#パリティビット自体はこれでいいだろう\n",
        "#もともと3層のはず。\n",
        "#出力は、3,3,1を3,3,2にすればよいのか？\n",
        "#それと、yも要素数2にするのか？\n",
        "#交差エントロピーはtorch.nn.CrossEntropyLoss()使うんだろうか。\n",
        "#交差エントロピー\n",
        "#ニューラルネットワークの出力が確率分布とみなせる時、目的の確率分布との差を評価する誤差関数。出力層がSoftmax関数を活性化関数としている場合などに用いられる。\n",
        "#−∑i=1K{ynilny^ni+(1−yni)ln(1−y^ni)}\n",
        "#softmax関数が組み込まれている点に注意\n",
        "\n",
        "#sigmoidを交差エントロピーに変えれば良い？\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, output_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    h = self.l1(x).softmax(0)#中間層は処理する必要？\n",
        "    return self.l2(h).softmax(0)#出力はそのまま、あとで交差エントロピー法のため？\n",
        "\n",
        "x = torch.tensor([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]], dtype=torch.float)\n",
        "y = torch.tensor([[1,0], [0,1], [0,1], [1,0], [0,1], [1,0], [1,0], [0,1]], dtype=torch.float)\n",
        "#出力層1ビットの場合は、0か1を出力すれば良かったが、今は出力層が2である。\n",
        "#1,0か0,1を出力させたくて、入力3ビットのうち、1の個数が偶数なら0を出力したい。\n",
        "#交差エントロピーなので、差を出したいから、もう片方を大きい値にする必要があり、\n",
        "#合計1にしておくことで、確率的な分布が出てくる。\n",
        "\n",
        "model = MLP(3, 3, 2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "history = []\n",
        "max_epoch = 100000\n",
        "for epoch in range(max_epoch):\n",
        "  pred = model(x)\n",
        "  error = criterion(y, pred)\n",
        "  history.append(error.item())\n",
        "  model.zero_grad()\n",
        "  error.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "history = np.array(history, dtype=np.float32)\n",
        "epochs = np.arange(1, max_epoch+1)\n",
        "plt.plot(epochs, history)\n",
        "plt.show()\n",
        "\n",
        "print(model(torch.tensor([0.0,0.0,0.0])))\n",
        "print(model(torch.tensor([0.0,0.0,1.0])))\n",
        "print(model(torch.tensor([0.0,1.0,0.0])))\n",
        "print(model(torch.tensor([0.0,1.0,1.0])))\n",
        "print(model(torch.tensor([1.0,0.0,0.0])))\n",
        "print(model(torch.tensor([1.0,0.0,1.0])))\n",
        "print(model(torch.tensor([1.0,1.0,0.0])))\n",
        "print(model(torch.tensor([1.0,1.0,1.0])))"
      ],
      "metadata": {
        "id": "MEz1SdysrZUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "b64feba0-d95c-4df0-f1a5-1cabef6ccfc3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.9998e-01, 2.4566e-05], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([1.0000e+00, 1.2387e-08], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([1.0000e+00, 1.7263e-16], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([1.0000e+00, 1.1475e-17], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.7023, 0.2977], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}